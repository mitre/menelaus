{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Drift Detector Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The examples in this noteboko show how to set up, run, and produce output from detectors in the \n",
    "concept_drift module. The parameters aren't necessarily tuned for best \n",
    "performance for the input data, just notional.\n",
    "\n",
    "Circle is a synthetic data source, where drift occurs in both var1, var2, and the \n",
    "conditional distributions P(y|var1) and P(y|var2). The drift occurs from index \n",
    "1000 to 1250, and affects 66% of the sample.\n",
    "\n",
    "These detectors are generally to be applied to the true class and predicted class \n",
    "from a particular model. ADWIN is an exception in that it could also be used to \n",
    "monitor an arbitrary real-valued feature. So, each of the summary plots displays \n",
    "the running accuracy of the classifier alongside the drift detector's output.\n",
    "\n",
    "They also track the indices of portions of the incoming data stream which are \n",
    "more similar to each other -- i.e., data that seems to be part of the same \n",
    "concept, which could be used to retrain a model.\n",
    "\n",
    "NOTE: The LinearFourRates example has a relatively long runtime, roughly 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports ##\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from menelaus.concept_drift import LinearFourRates, ADWIN, DDM, EDDM, STEPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Data ##\n",
    "\n",
    "# read in Circle dataset\n",
    "df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        \"..\", \"..\", \"..\", \"..\", \"src\", \"menelaus\", \"tools\", \"artifacts\", \"dataCircleGSev3Sp3Train.csv\"\n",
    "    ),\n",
    "    usecols=[0, 1, 2],\n",
    "    names=[\"var1\", \"var2\", \"y\"],\n",
    ")\n",
    "drift_start, drift_end = 1000, 1250\n",
    "training_size = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Four Rates (LFR) Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Four Rates monitors the four cells of the confusion matrix (TPR, FPR, TNR, FNR) and alarms when one of these becomes different enough from earlier performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup ##\n",
    "\n",
    "# Set up classifier: train on first training_size rows\n",
    "X_train = df.loc[0:training_size, [\"var1\", \"var2\"]]\n",
    "y_train = df.loc[0:training_size, \"y\"]\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Set up LFR detector to detect at significance of .001. 5000 Monte Carlo\n",
    "# simulations will be run every 10 samples to detect drift.\n",
    "lfr = LinearFourRates(\n",
    "    time_decay_factor=0.6,\n",
    "    warning_level=0.01,\n",
    "    detect_level=0.001,\n",
    "    num_mc=5000,\n",
    "    burn_in=10,\n",
    "    subsample=10,\n",
    ")\n",
    "\n",
    "# Set up DF to store results.\n",
    "status = pd.DataFrame(columns=[\"index\", \"y\", \"y_pred\", \"drift_detected\", \"accuracy\"])\n",
    "correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run LFR ##\n",
    "\n",
    "np.random.seed(123)  # set seed for this example\n",
    "\n",
    "# Run LFR and retrain.\n",
    "\n",
    "rec_list = []\n",
    "n = 1\n",
    "for i in range(training_size, len(df)):\n",
    "    X_test = df.loc[[i], [\"var1\", \"var2\"]]\n",
    "    y_pred = int(clf.predict(X_test))\n",
    "    y_true = int(df.loc[[i], \"y\"])\n",
    "\n",
    "    # increment accuracy\n",
    "    if y_pred == y_true:\n",
    "        correct += 1\n",
    "    accuracy = correct / n\n",
    "\n",
    "    lfr.update(y_pred, y_true)\n",
    "    status.loc[i] = [i, y_true, y_pred, lfr.drift_state, accuracy]\n",
    "\n",
    "    # If drift is detected, examine the retraining recommendations and retrain.\n",
    "    if lfr.drift_state == \"drift\":\n",
    "\n",
    "        retrain_start = lfr.retraining_recs[0] + training_size\n",
    "        retrain_end = lfr.retraining_recs[1] + training_size\n",
    "        if (\n",
    "            retrain_start == retrain_end\n",
    "        ):  # minimum retraining window in case of sudden drift\n",
    "            retrain_start = max(0, retrain_start - 300)\n",
    "        rec_list.append([retrain_start, retrain_end])\n",
    "\n",
    "        # If retraining is not desired, omit the next four lines.\n",
    "        X_train = df.loc[retrain_start:retrain_end, [\"var1\", \"var2\"]]\n",
    "        y_train = df.loc[retrain_start:retrain_end, \"y\"]\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting ##\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.scatter(\"index\", \"accuracy\", data=status, label=\"Accuracy\")\n",
    "plt.grid(False, axis=\"x\")\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.title(\"LFR Results: Accuracy\", fontsize=22)\n",
    "plt.ylabel(\"Value\", fontsize=18)\n",
    "plt.xlabel(\"Index\", fontsize=18)\n",
    "ylims = [-0.05, 1.1]\n",
    "plt.ylim(ylims)\n",
    "\n",
    "plt.axvspan(1000, 1250, alpha=0.5, label=\"Drift Induction Window\")\n",
    "\n",
    "# Draw red lines that indicate where drift was detected\n",
    "plt.vlines(\n",
    "    x=status.loc[status[\"drift_detected\"] == \"drift\"][\"index\"],\n",
    "    ymin=ylims[0],\n",
    "    ymax=ylims[1],\n",
    "    label=\"Drift Detected\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "# Draw orange lines that indicate where warnings of drift were provided\n",
    "plt.vlines(\n",
    "    x=status.loc[status[\"drift_detected\"] == \"warning\"][\"index\"],\n",
    "    ymin=ylims[0],\n",
    "    ymax=ylims[1],\n",
    "    label=\"Warning\",\n",
    "    color=\"orange\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "\n",
    "# Create a list of lines that indicate the retraining windows.\n",
    "# Space them evenly, vertically.\n",
    "rec_list = pd.DataFrame(rec_list)\n",
    "rec_list[\"y_val\"] = np.linspace(\n",
    "    start=0.05 * (ylims[1] - ylims[0]) + ylims[0],\n",
    "    stop=0.2 * ylims[1],\n",
    "    num=len(rec_list),\n",
    ")\n",
    "\n",
    "# Draw green lines that indicate where retraining occurred\n",
    "plt.hlines(\n",
    "    y=rec_list[\"y_val\"],\n",
    "    xmin=rec_list[0],\n",
    "    xmax=rec_list[1],\n",
    "    color=\"green\",\n",
    "    label=\"Retraining Windows\",\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# One of the four rates immediately passes outside its threshold when drift is\n",
    "# induced. The same occurs shortly after leaving the drift region. The\n",
    "# recommended retraining data includes most of the drift induction window and\n",
    "# the data after regime change.\n",
    "#\n",
    "# The classifier's accuracy decreases again later, which causes the detector to\n",
    "# enter a \"warning\" state. Note that the retraining recommendations *begin* with\n",
    "# the index corresponding to the warning state, and end where drift is detected.\n",
    "#\n",
    "\n",
    "# plt.savefig(\"example_LFR.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADaptive WINdowing (ADWIN) Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADWIN can be used to monitor the average of a given real-valued feature. In this case, we use it to monitor the accuracy of a classifier. ADWIN maintains a window of the data stream, which grows to the right as new elements are received. When the mean of the feature in one of the subwindows is different enough, ADWIN drops older elements in its window until this ceases to be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup ##\n",
    "\n",
    "# Set up classifier: train on first training_size rows\n",
    "X_train = df.loc[0:training_size, [\"var1\", \"var2\"]]\n",
    "y_train = df.loc[0:training_size, \"y\"]\n",
    "\n",
    "np.random.seed(123)\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "adwin = ADWIN()\n",
    "\n",
    "# Set up DF to record results.\n",
    "status = pd.DataFrame(\n",
    "    columns=[\"index\", \"results\", \"accuracy\", \"adwin mean\", \"drift_detected\"]\n",
    ")\n",
    "correct = 0\n",
    "rec_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run ADWIN\n",
    "n = 1\n",
    "for i in range(training_size, len(df)):\n",
    "\n",
    "    X_test = df.loc[[i], [\"var1\", \"var2\"]]\n",
    "    y_pred = int(clf.predict(X_test))\n",
    "    y_true = int(df.loc[[i], \"y\"])\n",
    "\n",
    "    # increment accuracy\n",
    "    if y_pred == y_true:\n",
    "        correct += 1\n",
    "    accuracy = correct / n\n",
    "\n",
    "    adwin.update(int(y_true == y_pred))\n",
    "    status.loc[i] = [\n",
    "        i,\n",
    "        int(y_true == y_pred),\n",
    "        accuracy,\n",
    "        adwin.mean(),\n",
    "        adwin.drift_state,\n",
    "    ]\n",
    "\n",
    "    # If drift is detected, examine the window and retrain.\n",
    "    if adwin.drift_state == \"drift\":\n",
    "        retrain_start = adwin.retraining_recs[0] + training_size\n",
    "        retrain_end = adwin.retraining_recs[1] + training_size\n",
    "        rec_list.append([retrain_start, retrain_end])\n",
    "\n",
    "        # The retraining recommendations produced here correspond to the samples\n",
    "        # which belong to ADWIN's new, smaller window, after drift is detected.\n",
    "        # If retraining is not desired, omit the next four lines.\n",
    "        X_train = df.loc[retrain_start:retrain_end, [\"var1\", \"var2\"]]\n",
    "        y_train = df.loc[retrain_start:retrain_end, \"y\"]\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting ##\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.scatter(\"index\", \"accuracy\", data=status, label=\"Accuracy\")\n",
    "plt.grid(False, axis=\"x\")\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.title(\"ADWIN Results: Accuracy\", fontsize=22)\n",
    "plt.ylabel(\"Value\", fontsize=18)\n",
    "plt.xlabel(\"Index\", fontsize=18)\n",
    "ylims = [0, 1.1]\n",
    "plt.ylim(ylims)\n",
    "\n",
    "plt.axvspan(1000, 1250, alpha=0.5, label=\"Drift Induction Window\")\n",
    "\n",
    "# Draw red lines that indicate where drift was detected\n",
    "plt.vlines(\n",
    "    x=status.loc[status[\"drift_detected\"] == \"drift\"][\"index\"],\n",
    "    ymin=ylims[0],\n",
    "    ymax=ylims[1],\n",
    "    label=\"Drift Detected\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "# Create a list of lines that indicate the retraining windows.\n",
    "# Space them evenly, vertically.\n",
    "rec_list = pd.DataFrame(rec_list)\n",
    "rec_list[\"y_val\"] = np.linspace(\n",
    "    start=0.05 * (ylims[1] - ylims[0]) + ylims[0],\n",
    "    stop=0.2 * ylims[1],\n",
    "    num=len(rec_list),\n",
    ")\n",
    "\n",
    "# Draw green lines that indicate where retraining occurred\n",
    "plt.hlines(\n",
    "    y=rec_list[\"y_val\"],\n",
    "    xmin=rec_list[0],\n",
    "    xmax=rec_list[1],\n",
    "    color=\"green\",\n",
    "    label=\"Retraining Windows\",\n",
    ")\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# After drift is induced, the accuracy decreases enough for ADWIN to shrink its\n",
    "# window and alarm;  subsequent windows also include data from the old regime,\n",
    "# so drift continues to be detected until the window shrinks enough to be\n",
    "# comprised mostly by the new regime.\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"example_ADWIN.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drift Detection Method (DDM) Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DDM can enter either a \"drift\" or \"warning\" state, depending on how close a classifier's error rate has approached to those respective thresholds, defined by the warning_scale and drift_scale parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup ##\n",
    "\n",
    "np.random.seed(123)\n",
    "# setup classifier: train on first training_size rows\n",
    "X_train = df.loc[0:training_size, [\"var1\", \"var2\"]]\n",
    "y_train = df.loc[0:training_size, \"y\"]\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# These parameter values are chosen somewhat arbitrarily.\n",
    "# At least 100 samples must be seen before DDM tests for drift (the n_threshold\n",
    "# parameter); the other two define the warning and drift regions. The minimum\n",
    "# error rate (and its standard deviation) are found during a stable regime; the\n",
    "# warning_scale and drift_scale roughly correspond to how many standard standard\n",
    "# deviations away the current estimate must be in order for the detector to\n",
    "# alarm.\n",
    "ddm = DDM(n_threshold=100, warning_scale=7, drift_scale=10)\n",
    "\n",
    "# setup DF to store results\n",
    "status = pd.DataFrame(columns=[\"index\", \"y\", \"y_pred\", \"drift_detected\", \"accuracy\"])\n",
    "correct = 0\n",
    "rec_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run DDM and retrain\n",
    "n = 1\n",
    "for i in range(training_size, len(df)):\n",
    "\n",
    "    X_test = df.loc[[i], [\"var1\", \"var2\"]]\n",
    "    y_pred = int(clf.predict(X_test))\n",
    "    y_true = int(df.loc[[i], \"y\"])\n",
    "\n",
    "    # increment accuracy\n",
    "    if y_pred == y_true:\n",
    "        correct += 1\n",
    "    accuracy = correct / n\n",
    "\n",
    "    ddm.update(y_pred, y_true)\n",
    "    status.loc[i] = [i, y_true, y_pred, ddm.drift_state, accuracy]\n",
    "\n",
    "    # If drift is detected, examine the window and retrain.\n",
    "    if ddm.drift_state == \"drift\":\n",
    "        retrain_start = ddm.retraining_recs[0] + training_size\n",
    "        retrain_end = ddm.retraining_recs[1] + training_size\n",
    "        if (\n",
    "            retrain_start == retrain_end\n",
    "        ):  # minimum retraining window in case of sudden drift\n",
    "            retrain_start = max(0, retrain_start - 300)\n",
    "        rec_list.append([retrain_start, retrain_end])\n",
    "\n",
    "        # If retraining is not desired, omit the next four lines.\n",
    "        X_train = df.loc[retrain_start:retrain_end, [\"var1\", \"var2\"]]\n",
    "        y_train = df.loc[retrain_start:retrain_end, \"y\"]\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting ##\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.scatter(\"index\", \"accuracy\", data=status, label=\"Accuracy\")\n",
    "plt.grid(False, axis=\"x\")\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.title(\"DDM Results: Accuracy\", fontsize=22)\n",
    "plt.ylabel(\"Value\", fontsize=18)\n",
    "plt.xlabel(\"Index\", fontsize=18)\n",
    "ylims = [-0.05, 1.1]\n",
    "plt.ylim(ylims)\n",
    "\n",
    "plt.axvspan(1000, 1250, alpha=0.5, label=\"Drift Induction Window\")\n",
    "\n",
    "# Draw red lines that indicate where drift was detected\n",
    "plt.vlines(\n",
    "    x=status.loc[status[\"drift_detected\"] == \"drift\"][\"index\"],\n",
    "    ymin=ylims[0],\n",
    "    ymax=ylims[1],\n",
    "    label=\"Drift Detected\",\n",
    "    color=\"red\",\n",
    "    linewidth=3,\n",
    ")\n",
    "\n",
    "# Draw orange lines that indicate where warnings of drift were provided\n",
    "plt.vlines(\n",
    "    x=status.loc[status[\"drift_detected\"] == \"warning\"][\"index\"],\n",
    "    ymin=ylims[0],\n",
    "    ymax=ylims[1],\n",
    "    label=\"Warning\",\n",
    "    color=\"orange\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "\n",
    "# Create a list of lines that indicate the retraining windows.\n",
    "# Space them evenly, vertically.\n",
    "rec_list = pd.DataFrame(rec_list)\n",
    "rec_list[\"y_val\"] = np.linspace(\n",
    "    start=0.05 * (ylims[1] - ylims[0]) + ylims[0],\n",
    "    stop=0.2 * ylims[1],\n",
    "    num=len(rec_list),\n",
    ")\n",
    "\n",
    "# Draw green lines that indicate where retraining occurred\n",
    "plt.hlines(\n",
    "    y=rec_list[\"y_val\"],\n",
    "    xmin=rec_list[0],\n",
    "    xmax=rec_list[1],\n",
    "    color=\"green\",\n",
    "    label=\"Retraining Windows\",\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# DDM initially alarms during the drift induction window, triggering retraining.\n",
    "# The subsequent dip in accuracy is large enough to put the detector in the\n",
    "# \"warning\" state, but not large enough for \"drift\" to be identified.\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"example_DDM.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Drift Detection Method (EDDM) Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDDM monitors the distance between two errors of a classifier - i.e., the number of samples between errors - rather than monitoring the error rate itself. Similar to DDM, it uses separate thresholds for \"warning\" and \"drift.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup ##\n",
    "\n",
    "np.random.seed(123)\n",
    "# setup classifier: train on first 500 rows\n",
    "X_train = df.loc[0:training_size, [\"var1\", \"var2\"]]\n",
    "y_train = df.loc[0:training_size, \"y\"]\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# n_threshold specifies the number of new samples which must be observed before\n",
    "# tests for drift are run.\n",
    "# The warning_thresh and drift_thresh values roughly correspond to the ratio of\n",
    "# the 95th percentile for the current distance distribution vs. the 95th percentile\n",
    "# for the \"best\" distance distribution observed so far.\n",
    "# So, lower values correspond to less conservative monitoring - the current\n",
    "# distance between errors is allowed to be a smaller fraction of the \"best\"\n",
    "# distance.\n",
    "eddm = EDDM(n_threshold=30, warning_thresh=0.7, drift_thresh=0.5)\n",
    "\n",
    "# setup DF to store results\n",
    "status = pd.DataFrame(columns=[\"index\", \"y\", \"y_pred\", \"drift_detected\", \"accuracy\"])\n",
    "correct = 0\n",
    "rec_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run EDDM and retrain\n",
    "n = 1\n",
    "for i in range(training_size, len(df)):\n",
    "\n",
    "    X_test = df.loc[[i], [\"var1\", \"var2\"]]\n",
    "    y_pred = int(clf.predict(X_test))\n",
    "    y_true = int(df.loc[[i], \"y\"])\n",
    "\n",
    "    # increment accuracy\n",
    "    if y_pred == y_true:\n",
    "        correct += 1\n",
    "    accuracy = correct / n\n",
    "\n",
    "    eddm.update(y_pred, y_true)\n",
    "    status.loc[i] = [i, y_true, y_pred, eddm.drift_state, accuracy]\n",
    "\n",
    "    # If drift is detected, examine the window and retrain.\n",
    "    if eddm.drift_state == \"drift\":\n",
    "        retrain_start = eddm.retraining_recs[0] + training_size\n",
    "        retrain_end = eddm.retraining_recs[1] + training_size\n",
    "        if (\n",
    "            retrain_start == retrain_end\n",
    "        ):  # minimum retraining window in case of sudden drift\n",
    "            retrain_start = max(0, retrain_start - 300)\n",
    "        rec_list.append([retrain_start, retrain_end])\n",
    "\n",
    "        # If retraining is not desired, omit the next four lines.\n",
    "        X_train = df.loc[retrain_start:retrain_end, [\"var1\", \"var2\"]]\n",
    "        y_train = df.loc[retrain_start:retrain_end, \"y\"]\n",
    "        clf = GaussianNB()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting ##\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.scatter(\"index\", \"accuracy\", data=status, label=\"Accuracy\")\n",
    "plt.grid(False, axis=\"x\")\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.title(\"EDDM Results: Accuracy\", fontsize=22)\n",
    "plt.ylabel(\"Value\", fontsize=18)\n",
    "plt.xlabel(\"Index\", fontsize=18)\n",
    "ylims = [-0.05, 1.1]\n",
    "plt.ylim(ylims)\n",
    "\n",
    "plt.axvspan(1000, 1250, alpha=0.5, label=\"Drift Induction Window\")\n",
    "\n",
    "# Draw orange lines that indicate where warnings of drift were provided\n",
    "plt.vlines(\n",
    "    x=status.loc[status[\"drift_detected\"] == \"warning\"][\"index\"],\n",
    "    ymin=ylims[0],\n",
    "    ymax=ylims[1],\n",
    "    label=\"Warning\",\n",
    "    color=\"orange\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "\n",
    "# Draw red lines that indicate where drift was detected\n",
    "plt.vlines(\n",
    "    x=status.loc[status[\"drift_detected\"] == \"drift\"][\"index\"],\n",
    "    ymin=ylims[0],\n",
    "    ymax=ylims[1],\n",
    "    label=\"Drift Detected\",\n",
    "    color=\"red\",\n",
    ")\n",
    "\n",
    "# Create a list of lines that indicate the retraining windows.\n",
    "# Space them evenly, vertically.\n",
    "rec_list = pd.DataFrame(rec_list)\n",
    "rec_list[\"y_val\"] = np.linspace(\n",
    "    start=0.05 * (ylims[1] - ylims[0]) + ylims[0],\n",
    "    stop=0.2 * ylims[1],\n",
    "    num=len(rec_list),\n",
    ")\n",
    "\n",
    "# Draw green lines that indicate where retraining occurred\n",
    "plt.hlines(\n",
    "    y=rec_list[\"y_val\"],\n",
    "    xmin=rec_list[0],\n",
    "    xmax=rec_list[1],\n",
    "    color=\"green\",\n",
    "    label=\"Retraining Windows\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# EDDM enters a drift state shortly after the drift induction window, triggering\n",
    "# retraining. The later increase in the error rate causes the detector to enter\n",
    "# the warning state, but is not large enough to be identified as drift with this\n",
    "# threshold setting.\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"example_EDDM.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Test of Equal Proportions to Detect Concept Drift (STEPD) Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEPD is a detector specifically intended for online classifiers, where each new sample is used to update the parameters of the classifier. STEPD monitors the accuracy in two windows, \"recent\" and \"past,\" and compares those in order to detect drift in classifier accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup ##\n",
    "\n",
    "np.random.seed(123)\n",
    "df_ex = df\n",
    "train_ix = [0, training_size]\n",
    "\n",
    "\n",
    "# For the purposes of this example, our online classifier is an SGDClassifier\n",
    "# with a constant learning rate, since this is available in the pre-existing\n",
    "# package dependency sklearn.\n",
    "clf = SGDClassifier(learning_rate=\"constant\", shuffle=False, eta0=0.2)\n",
    "clf.fit(\n",
    "    df_ex.loc[train_ix[0] : train_ix[1], [\"var1\", \"var2\"]].values,\n",
    "    df_ex.loc[train_ix[0] : train_ix[1], \"y\"].values,\n",
    ")\n",
    "\n",
    "\n",
    "stepd = STEPD(window_size=100)\n",
    "\n",
    "# setup DF to store results\n",
    "status = pd.DataFrame(columns=[\"index\", \"y\", \"y_pred\", \"drift_detected\", \"accuracy\"])\n",
    "correct = 0\n",
    "rec_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run STEPD and retrain\n",
    "n = 1\n",
    "for i, row in df_ex.iloc[training_size:].iterrows():\n",
    "    y_pred = clf.predict(np.array(row[[\"var1\", \"var2\"]]).reshape(1, -1))\n",
    "    y_true = row[\"y\"]\n",
    "\n",
    "    if y_pred == y_true:\n",
    "        correct += 1\n",
    "    accuracy = correct / n\n",
    "\n",
    "    stepd.update(y_pred, y_true)\n",
    "    status.loc[i] = [i, y_true, y_pred, stepd.drift_state, accuracy]\n",
    "    # train_ix[1] = train_ix[1] + 1\n",
    "\n",
    "    if stepd.drift_state == \"drift\":\n",
    "        rec_list.append(stepd.retraining_recs)\n",
    "        # retrain the classifier using STEPD's recommendations\n",
    "        train_ix = stepd.retraining_recs\n",
    "        train_ix[0] = train_ix[0] + training_size  # adjust for starting index\n",
    "        train_ix[1] = train_ix[1] + training_size\n",
    "        clf.fit(\n",
    "            df_ex.loc[train_ix[0] : train_ix[1], [\"var1\", \"var2\"]].values,\n",
    "            df_ex.loc[train_ix[0] : train_ix[1], \"y\"].values,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        # update the classifier with the newest sample\n",
    "        clf.partial_fit(row[[\"var1\", \"var2\"]].values.reshape(1, -1), [row[\"y\"]])\n",
    "\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting ##\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.scatter(\"index\", \"accuracy\", data=status, label=\"Accuracy\")\n",
    "plt.grid(False, axis=\"x\")\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.title(\"STEPD Results: Accuracy\", fontsize=22)\n",
    "plt.ylabel(\"Value\", fontsize=18)\n",
    "plt.xlabel(\"Index\", fontsize=18)\n",
    "ylims = [-0.05, 1.1]\n",
    "plt.ylim(ylims)\n",
    "\n",
    "plt.axvspan(1000, 1250, alpha=0.5, label=\"Drift Induction Window\")\n",
    "\n",
    "# Draw orange lines that indicate where warnings of drift were provided\n",
    "plt.vlines(\n",
    "    x=status.loc[status[\"drift_detected\"] == \"warning\"][\"index\"],\n",
    "    ymin=ylims[0],\n",
    "    ymax=ylims[1],\n",
    "    label=\"Warning\",\n",
    "    color=\"orange\",\n",
    "    alpha=0.3,\n",
    ")\n",
    "\n",
    "# Draw red lines that indicate where drift was detected\n",
    "plt.vlines(\n",
    "    x=status.loc[status[\"drift_detected\"] == \"drift\"][\"index\"],\n",
    "    ymin=ylims[0],\n",
    "    ymax=ylims[1],\n",
    "    label=\"Drift Detected\",\n",
    "    color=\"red\",\n",
    "    linewidth=3,\n",
    ")\n",
    "\n",
    "# Create a list of lines that indicate the retraining windows.\n",
    "# Space them evenly, vertically.\n",
    "rec_list = pd.DataFrame(rec_list)\n",
    "rec_list[\"y_val\"] = np.linspace(\n",
    "    start=0.05 * (ylims[1] - ylims[0]) + ylims[0],\n",
    "    stop=0.2 * ylims[1],\n",
    "    num=len(rec_list),\n",
    ")\n",
    "\n",
    "# Draw green lines that indicate where retraining occurred\n",
    "plt.hlines(\n",
    "    y=rec_list[\"y_val\"],\n",
    "    xmin=rec_list[0],\n",
    "    xmax=rec_list[1],\n",
    "    color=\"green\",\n",
    "    label=\"Retraining Windows\",\n",
    ")\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# STEPD identifies drift quite early in the drift induction window, triggering\n",
    "# retraining on a relatively small amount of data; after this, the online\n",
    "# classifier updates sufficiently that its accuracy is roughly flat over the\n",
    "# remaining data, albeit with a big enough change to trigger more warnings.\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(\"example_STEPD.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

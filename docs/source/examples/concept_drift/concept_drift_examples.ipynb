{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Concept Drift Detector Examples"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The examples in this notebook show how to set up, run, and produce output from detectors in the \n",
                "concept_drift module. The parameters aren't necessarily tuned for best \n",
                "performance for the input data, just notional.\n",
                "\n",
                "Circle is a synthetic data source, where drift occurs in both var1, var2, and the \n",
                "conditional distributions P(y|var1) and P(y|var2). The drift occurs from index \n",
                "1000 to 1250, and affects 66% of the sample.\n",
                "\n",
                "Rainfall is a real data source that concept drift has been injected into. This\n",
                "set contains approximately 18,000 samples, and the data has been standardized.\n",
                "Drift starts from index 12,000 and continues through the rest of the dataset.\n",
                "In this example, we take the first 10,000 samples of the dataset for training\n",
                "an initial classifier, and then use the remaining samples for testing.\n",
                "\n",
                "These detectors are generally to be applied to the true class and predicted class \n",
                "from a particular model. So, each of the summary plots displays the running\n",
                "accuracy of the classifier alongside the drift detector's output.\n",
                "\n",
                "They also track the indices of portions of the incoming data stream which are \n",
                "more similar to each other -- i.e., data that seems to be part of the same \n",
                "concept, which could be used to retrain a model.\n",
                "\n",
                "NOTE: The LinearFourRates example has a relatively long runtime, roughly 5 minutes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Imports ##\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.linear_model import SGDClassifier\n",
                "from sklearn import svm\n",
                "from sklearn.base import clone\n",
                "from menelaus.concept_drift import LinearFourRates, ADWIN, DDM, EDDM, STEPD, MD3\n",
                "from menelaus.datasets import fetch_circle_data\n",
                "from menelaus.datasets import fetch_rainfall_data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Import Data ##\n",
                "\n",
                "# read in Circle dataset\n",
                "df = fetch_circle_data()\n",
                "drift_start, drift_end = 1000, 1250\n",
                "training_size = 500\n",
                "\n",
                "# read in Rainfall dataset\n",
                "rainfall_df = fetch_rainfall_data()\n",
                "rainfall_drift_start, rainfall_drift_end = 12000, 18158\n",
                "rainfall_training_size = 10000\n",
                "rainfall_columns = [\"temperature\", \"dew_point\", \"sea_level_pressure\", \"visibility\", \"average_wind_speed\", \"max_sustained_wind_speed\", \"minimum_temperature\", \"maximum_temperature\", \"rain\"]\n",
                "rainfall_features = [\"temperature\", \"dew_point\", \"sea_level_pressure\", \"visibility\", \"average_wind_speed\", \"max_sustained_wind_speed\", \"minimum_temperature\", \"maximum_temperature\"]\n",
                "rainfall_df[rainfall_features] = rainfall_df[rainfall_features].astype(float)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Linear Four Rates (LFR)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Linear Four Rates monitors the four cells of the confusion matrix (TPR, FPR, TNR, FNR) and alarms when one of these becomes different enough from earlier performance."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Setup ##\n",
                "\n",
                "# Set up classifier: train on first training_size rows\n",
                "X_train = df.loc[0:training_size, [\"var1\", \"var2\"]]\n",
                "y_train = df.loc[0:training_size, \"y\"]\n",
                "clf = GaussianNB()\n",
                "clf.fit(X_train, y_train)\n",
                "\n",
                "# Set up LFR detector to detect at significance of .001. 5000 Monte Carlo\n",
                "# simulations will be run every 10 samples to detect drift.\n",
                "lfr = LinearFourRates(\n",
                "    time_decay_factor=0.6,\n",
                "    warning_level=0.01,\n",
                "    detect_level=0.001,\n",
                "    num_mc=5000,\n",
                "    burn_in=10,\n",
                "    subsample=10,\n",
                ")\n",
                "\n",
                "# Set up DF to store results.\n",
                "status = pd.DataFrame(columns=[\"index\", \"y\", \"y_pred\", \"drift_detected\", \"accuracy\"])\n",
                "correct = 0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Run LFR ##\n",
                "\n",
                "np.random.seed(123)  # set seed for this example\n",
                "\n",
                "# Run LFR and retrain.\n",
                "\n",
                "rec_list = []\n",
                "n = 1\n",
                "for i in range(training_size, len(df)):\n",
                "    X_test = df.loc[[i], [\"var1\", \"var2\"]]\n",
                "    y_pred = int(clf.predict(X_test))\n",
                "    y_true = int(df.loc[[i], \"y\"])\n",
                "\n",
                "    # increment accuracy\n",
                "    if y_pred == y_true:\n",
                "        correct += 1\n",
                "    accuracy = correct / n\n",
                "\n",
                "    lfr.update(y_true, y_pred)\n",
                "    status.loc[i] = [i, y_true, y_pred, lfr.drift_state, accuracy]\n",
                "\n",
                "    # If drift is detected, examine the retraining recommendations and retrain.\n",
                "    if lfr.drift_state == \"drift\":\n",
                "\n",
                "        retrain_start = lfr.retraining_recs[0] + training_size\n",
                "        retrain_end = lfr.retraining_recs[1] + training_size\n",
                "        if (\n",
                "            retrain_start == retrain_end\n",
                "        ):  # minimum retraining window in case of sudden drift\n",
                "            retrain_start = max(0, retrain_start - 300)\n",
                "        rec_list.append([retrain_start, retrain_end])\n",
                "\n",
                "        # If retraining is not desired, omit the next four lines.\n",
                "        X_train = df.loc[retrain_start:retrain_end, [\"var1\", \"var2\"]]\n",
                "        y_train = df.loc[retrain_start:retrain_end, \"y\"]\n",
                "        clf = GaussianNB()\n",
                "        clf.fit(X_train, y_train)\n",
                "\n",
                "    n += 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Plotting ##\n",
                "\n",
                "plt.figure(figsize=(20, 5))\n",
                "plt.scatter(\"index\", \"accuracy\", data=status, label=\"Accuracy\")\n",
                "plt.grid(False, axis=\"x\")\n",
                "plt.xticks(fontsize=16)\n",
                "plt.yticks(fontsize=16)\n",
                "plt.title(\"LFR Results: Accuracy\", fontsize=22)\n",
                "plt.ylabel(\"Value\", fontsize=18)\n",
                "plt.xlabel(\"Index\", fontsize=18)\n",
                "ylims = [-0.05, 1.1]\n",
                "plt.ylim(ylims)\n",
                "\n",
                "plt.axvspan(1000, 1250, alpha=0.5, label=\"Drift Induction Window\")\n",
                "\n",
                "# Draw red lines that indicate where drift was detected\n",
                "plt.vlines(\n",
                "    x=status.loc[status[\"drift_detected\"] == \"drift\"][\"index\"],\n",
                "    ymin=ylims[0],\n",
                "    ymax=ylims[1],\n",
                "    label=\"Drift Detected\",\n",
                "    color=\"red\",\n",
                ")\n",
                "\n",
                "# Draw orange lines that indicate where warnings of drift were provided\n",
                "plt.vlines(\n",
                "    x=status.loc[status[\"drift_detected\"] == \"warning\"][\"index\"],\n",
                "    ymin=ylims[0],\n",
                "    ymax=ylims[1],\n",
                "    label=\"Warning\",\n",
                "    color=\"orange\",\n",
                "    alpha=0.3,\n",
                ")\n",
                "\n",
                "# Create a list of lines that indicate the retraining windows.\n",
                "# Space them evenly, vertically.\n",
                "rec_list = pd.DataFrame(rec_list)\n",
                "rec_list[\"y_val\"] = np.linspace(\n",
                "    start=0.05 * (ylims[1] - ylims[0]) + ylims[0],\n",
                "    stop=0.2 * ylims[1],\n",
                "    num=len(rec_list),\n",
                ")\n",
                "\n",
                "# Draw green lines that indicate where retraining occurred\n",
                "plt.hlines(\n",
                "    y=rec_list[\"y_val\"],\n",
                "    xmin=rec_list[0],\n",
                "    xmax=rec_list[1],\n",
                "    color=\"green\",\n",
                "    label=\"Retraining Windows\",\n",
                ")\n",
                "\n",
                "plt.legend()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "One of the four rates immediately passes outside its threshold when drift is\n",
                "induced. The same occurs shortly after leaving the drift region. The\n",
                "recommended retraining data includes most of the drift induction window and\n",
                "the data after regime change.\n",
                "\n",
                "The classifier's accuracy decreases again later, which causes the detector to\n",
                "enter a \"warning\" state. Note that the retraining recommendations *begin* with\n",
                "the index corresponding to the warning state, and end where drift is detected.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ADaptive WINdowing (ADWIN)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "ADWIN can be used to monitor the accuracy of a classifier. ADWIN maintains a window of the data stream, which grows to the right as new elements are received. When the mean of the feature in one of the subwindows is different enough, ADWIN drops older elements in its window until this ceases to be the case."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Setup ##\n",
                "\n",
                "# Set up classifier: train on first training_size rows\n",
                "X_train = df.loc[0:training_size, [\"var1\", \"var2\"]]\n",
                "y_train = df.loc[0:training_size, \"y\"]\n",
                "\n",
                "np.random.seed(123)\n",
                "clf = GaussianNB()\n",
                "clf.fit(X_train, y_train)\n",
                "\n",
                "adwin = ADWIN()\n",
                "\n",
                "# Set up DF to record results.\n",
                "status = pd.DataFrame(\n",
                "    columns=[\"index\", \"results\", \"accuracy\", \"adwin mean\", \"drift_detected\"]\n",
                ")\n",
                "correct = 0\n",
                "rec_list = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# run ADWIN\n",
                "n = 1\n",
                "for i in range(training_size, len(df)):\n",
                "\n",
                "    X_test = df.loc[[i], [\"var1\", \"var2\"]]\n",
                "    y_pred = int(clf.predict(X_test))\n",
                "    y_true = int(df.loc[[i], \"y\"])\n",
                "\n",
                "    # increment accuracy\n",
                "    if y_pred == y_true:\n",
                "        correct += 1\n",
                "    accuracy = correct / n\n",
                "\n",
                "    adwin.update(y_true, y_pred)\n",
                "    status.loc[i] = [\n",
                "        i,\n",
                "        int(y_true == y_pred),\n",
                "        accuracy,\n",
                "        adwin.mean(),\n",
                "        adwin.drift_state,\n",
                "    ]\n",
                "\n",
                "    # If drift is detected, examine the window and retrain.\n",
                "    if adwin.drift_state == \"drift\":\n",
                "        retrain_start = adwin.retraining_recs[0] + training_size\n",
                "        retrain_end = adwin.retraining_recs[1] + training_size\n",
                "        rec_list.append([retrain_start, retrain_end])\n",
                "\n",
                "        # The retraining recommendations produced here correspond to the samples\n",
                "        # which belong to ADWIN's new, smaller window, after drift is detected.\n",
                "        # If retraining is not desired, omit the next four lines.\n",
                "        X_train = df.loc[retrain_start:retrain_end, [\"var1\", \"var2\"]]\n",
                "        y_train = df.loc[retrain_start:retrain_end, \"y\"]\n",
                "        clf = GaussianNB()\n",
                "        clf.fit(X_train, y_train)\n",
                "\n",
                "    n += 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Plotting ##\n",
                "\n",
                "plt.figure(figsize=(20, 6))\n",
                "plt.scatter(\"index\", \"accuracy\", data=status, label=\"Accuracy\")\n",
                "plt.grid(False, axis=\"x\")\n",
                "plt.xticks(fontsize=16)\n",
                "plt.yticks(fontsize=16)\n",
                "plt.title(\"ADWIN Results: Accuracy\", fontsize=22)\n",
                "plt.ylabel(\"Value\", fontsize=18)\n",
                "plt.xlabel(\"Index\", fontsize=18)\n",
                "ylims = [0, 1.1]\n",
                "plt.ylim(ylims)\n",
                "\n",
                "plt.axvspan(1000, 1250, alpha=0.5, label=\"Drift Induction Window\")\n",
                "\n",
                "# Draw red lines that indicate where drift was detected\n",
                "plt.vlines(\n",
                "    x=status.loc[status[\"drift_detected\"] == \"drift\"][\"index\"],\n",
                "    ymin=ylims[0],\n",
                "    ymax=ylims[1],\n",
                "    label=\"Drift Detected\",\n",
                "    color=\"red\",\n",
                ")\n",
                "\n",
                "# Create a list of lines that indicate the retraining windows.\n",
                "# Space them evenly, vertically.\n",
                "rec_list = pd.DataFrame(rec_list)\n",
                "rec_list[\"y_val\"] = np.linspace(\n",
                "    start=0.05 * (ylims[1] - ylims[0]) + ylims[0],\n",
                "    stop=0.2 * ylims[1],\n",
                "    num=len(rec_list),\n",
                ")\n",
                "\n",
                "# Draw green lines that indicate where retraining occurred\n",
                "plt.hlines(\n",
                "    y=rec_list[\"y_val\"],\n",
                "    xmin=rec_list[0],\n",
                "    xmax=rec_list[1],\n",
                "    color=\"green\",\n",
                "    label=\"Retraining Windows\",\n",
                ")\n",
                "\n",
                "plt.legend(loc='lower right')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "After drift is induced, the accuracy decreases enough for ADWIN to shrink its\n",
                "window and alarm;  subsequent windows also include data from the old regime,\n",
                "so drift continues to be detected until the window shrinks enough to be\n",
                "comprised mostly by the new regime.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.show()\n",
                "# plt.savefig(\"example_ADWIN.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Drift Detection Method (DDM)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "DDM can enter either a \"drift\" or \"warning\" state, depending on how close a classifier's error rate has approached to those respective thresholds, defined by the warning_scale and drift_scale parameters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Setup ##\n",
                "\n",
                "np.random.seed(123)\n",
                "# setup classifier: train on first training_size rows\n",
                "X_train = df.loc[0:training_size, [\"var1\", \"var2\"]]\n",
                "y_train = df.loc[0:training_size, \"y\"]\n",
                "clf = GaussianNB()\n",
                "clf.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "These parameter values are chosen somewhat arbitrarily.\n",
                "At least 100 samples must be seen before DDM tests for drift (the n_threshold\n",
                "parameter); the other two define the warning and drift regions. The minimum\n",
                "error rate (and its standard deviation) are found during a stable regime; the\n",
                "warning_scale and drift_scale roughly correspond to how many standard standard\n",
                "deviations away the current estimate must be in order for the detector to\n",
                "alarm.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ddm = DDM(n_threshold=100, warning_scale=7, drift_scale=10)\n",
                "\n",
                "# setup DF to store results\n",
                "status = pd.DataFrame(columns=[\"index\", \"y\", \"y_pred\", \"drift_detected\", \"accuracy\"])\n",
                "correct = 0\n",
                "rec_list = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# run DDM and retrain\n",
                "n = 1\n",
                "for i in range(training_size, len(df)):\n",
                "\n",
                "    X_test = df.loc[[i], [\"var1\", \"var2\"]]\n",
                "    y_pred = int(clf.predict(X_test))\n",
                "    y_true = int(df.loc[[i], \"y\"])\n",
                "\n",
                "    # increment accuracy\n",
                "    if y_pred == y_true:\n",
                "        correct += 1\n",
                "    accuracy = correct / n\n",
                "\n",
                "    ddm.update(y_true, y_pred)\n",
                "    status.loc[i] = [i, y_true, y_pred, ddm.drift_state, accuracy]\n",
                "\n",
                "    # If drift is detected, examine the window and retrain.\n",
                "    if ddm.drift_state == \"drift\":\n",
                "        retrain_start = ddm.retraining_recs[0] + training_size\n",
                "        retrain_end = ddm.retraining_recs[1] + training_size\n",
                "        if (\n",
                "            retrain_start == retrain_end\n",
                "        ):  # minimum retraining window in case of sudden drift\n",
                "            retrain_start = max(0, retrain_start - 300)\n",
                "        rec_list.append([retrain_start, retrain_end])\n",
                "\n",
                "        # If retraining is not desired, omit the next four lines.\n",
                "        X_train = df.loc[retrain_start:retrain_end, [\"var1\", \"var2\"]]\n",
                "        y_train = df.loc[retrain_start:retrain_end, \"y\"]\n",
                "        clf = GaussianNB()\n",
                "        clf.fit(X_train, y_train)\n",
                "\n",
                "    n += 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Plotting ##\n",
                "\n",
                "plt.figure(figsize=(20, 6))\n",
                "plt.scatter(\"index\", \"accuracy\", data=status, label=\"Accuracy\")\n",
                "plt.grid(False, axis=\"x\")\n",
                "plt.xticks(fontsize=16)\n",
                "plt.yticks(fontsize=16)\n",
                "plt.title(\"DDM Results: Accuracy\", fontsize=22)\n",
                "plt.ylabel(\"Value\", fontsize=18)\n",
                "plt.xlabel(\"Index\", fontsize=18)\n",
                "ylims = [-0.05, 1.1]\n",
                "plt.ylim(ylims)\n",
                "\n",
                "plt.axvspan(1000, 1250, alpha=0.5, label=\"Drift Induction Window\")\n",
                "\n",
                "# Draw red lines that indicate where drift was detected\n",
                "plt.vlines(\n",
                "    x=status.loc[status[\"drift_detected\"] == \"drift\"][\"index\"],\n",
                "    ymin=ylims[0],\n",
                "    ymax=ylims[1],\n",
                "    label=\"Drift Detected\",\n",
                "    color=\"red\",\n",
                "    linewidth=3,\n",
                ")\n",
                "\n",
                "# Draw orange lines that indicate where warnings of drift were provided\n",
                "plt.vlines(\n",
                "    x=status.loc[status[\"drift_detected\"] == \"warning\"][\"index\"],\n",
                "    ymin=ylims[0],\n",
                "    ymax=ylims[1],\n",
                "    label=\"Warning\",\n",
                "    color=\"orange\",\n",
                "    alpha=0.3,\n",
                ")\n",
                "\n",
                "# Create a list of lines that indicate the retraining windows.\n",
                "# Space them evenly, vertically.\n",
                "rec_list = pd.DataFrame(rec_list)\n",
                "rec_list[\"y_val\"] = np.linspace(\n",
                "    start=0.05 * (ylims[1] - ylims[0]) + ylims[0],\n",
                "    stop=0.2 * ylims[1],\n",
                "    num=len(rec_list),\n",
                ")\n",
                "\n",
                "# Draw green lines that indicate where retraining occurred\n",
                "plt.hlines(\n",
                "    y=rec_list[\"y_val\"],\n",
                "    xmin=rec_list[0],\n",
                "    xmax=rec_list[1],\n",
                "    color=\"green\",\n",
                "    label=\"Retraining Windows\",\n",
                ")\n",
                "\n",
                "plt.legend()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "DDM initially alarms during the drift induction window, triggering retraining.\n",
                "The subsequent dip in accuracy is large enough to put the detector in the\n",
                "\"warning\" state, but not large enough for \"drift\" to be identified.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.show()\n",
                "# plt.savefig(\"example_DDM.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Early Drift Detection Method (EDDM)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "EDDM monitors the distance between two errors of a classifier - i.e., the number of samples between errors - rather than monitoring the error rate itself. Similar to DDM, it uses separate thresholds for \"warning\" and \"drift.\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Setup ##\n",
                "\n",
                "np.random.seed(123)\n",
                "# setup classifier: train on first 500 rows\n",
                "X_train = df.loc[0:training_size, [\"var1\", \"var2\"]]\n",
                "y_train = df.loc[0:training_size, \"y\"]\n",
                "clf = GaussianNB()\n",
                "clf.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- n_threshold specifies the number of new samples which must be observed before\n",
                "tests for drift are run.\n",
                "\n",
                "- The warning_thresh and drift_thresh values roughly correspond to the ratio of\n",
                "the 95th percentile for the current distance distribution vs. the 95th percentile\n",
                "for the \"best\" distance distribution observed so far. So, lower values correspond to less conservative monitoring - the current\n",
                "distance between errors is allowed to be a smaller fraction of the \"best\"\n",
                "distance.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "eddm = EDDM(n_threshold=30, warning_thresh=0.7, drift_thresh=0.5)\n",
                "\n",
                "# setup DF to store results\n",
                "status = pd.DataFrame(columns=[\"index\", \"y\", \"y_pred\", \"drift_detected\", \"accuracy\"])\n",
                "correct = 0\n",
                "rec_list = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# run EDDM and retrain\n",
                "n = 1\n",
                "for i in range(training_size, len(df)):\n",
                "\n",
                "    X_test = df.loc[[i], [\"var1\", \"var2\"]]\n",
                "    y_pred = int(clf.predict(X_test))\n",
                "    y_true = int(df.loc[[i], \"y\"])\n",
                "\n",
                "    # increment accuracy\n",
                "    if y_pred == y_true:\n",
                "        correct += 1\n",
                "    accuracy = correct / n\n",
                "\n",
                "    eddm.update(y_true, y_pred)\n",
                "    status.loc[i] = [i, y_true, y_pred, eddm.drift_state, accuracy]\n",
                "\n",
                "    # If drift is detected, examine the window and retrain.\n",
                "    if eddm.drift_state == \"drift\":\n",
                "        retrain_start = eddm.retraining_recs[0] + training_size\n",
                "        retrain_end = eddm.retraining_recs[1] + training_size\n",
                "        if (\n",
                "            retrain_start == retrain_end\n",
                "        ):  # minimum retraining window in case of sudden drift\n",
                "            retrain_start = max(0, retrain_start - 300)\n",
                "        rec_list.append([retrain_start, retrain_end])\n",
                "\n",
                "        # If retraining is not desired, omit the next four lines.\n",
                "        X_train = df.loc[retrain_start:retrain_end, [\"var1\", \"var2\"]]\n",
                "        y_train = df.loc[retrain_start:retrain_end, \"y\"]\n",
                "        clf = GaussianNB()\n",
                "        clf.fit(X_train, y_train)\n",
                "\n",
                "    n += 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Plotting ##\n",
                "\n",
                "plt.figure(figsize=(20, 6))\n",
                "plt.scatter(\"index\", \"accuracy\", data=status, label=\"Accuracy\")\n",
                "plt.grid(False, axis=\"x\")\n",
                "plt.xticks(fontsize=16)\n",
                "plt.yticks(fontsize=16)\n",
                "plt.title(\"EDDM Results: Accuracy\", fontsize=22)\n",
                "plt.ylabel(\"Value\", fontsize=18)\n",
                "plt.xlabel(\"Index\", fontsize=18)\n",
                "ylims = [-0.05, 1.1]\n",
                "plt.ylim(ylims)\n",
                "\n",
                "plt.axvspan(1000, 1250, alpha=0.5, label=\"Drift Induction Window\")\n",
                "\n",
                "# Draw orange lines that indicate where warnings of drift were provided\n",
                "plt.vlines(\n",
                "    x=status.loc[status[\"drift_detected\"] == \"warning\"][\"index\"],\n",
                "    ymin=ylims[0],\n",
                "    ymax=ylims[1],\n",
                "    label=\"Warning\",\n",
                "    color=\"orange\",\n",
                "    alpha=0.3,\n",
                ")\n",
                "\n",
                "# Draw red lines that indicate where drift was detected\n",
                "plt.vlines(\n",
                "    x=status.loc[status[\"drift_detected\"] == \"drift\"][\"index\"],\n",
                "    ymin=ylims[0],\n",
                "    ymax=ylims[1],\n",
                "    label=\"Drift Detected\",\n",
                "    color=\"red\",\n",
                ")\n",
                "\n",
                "# Create a list of lines that indicate the retraining windows.\n",
                "# Space them evenly, vertically.\n",
                "rec_list = pd.DataFrame(rec_list)\n",
                "rec_list[\"y_val\"] = np.linspace(\n",
                "    start=0.05 * (ylims[1] - ylims[0]) + ylims[0],\n",
                "    stop=0.2 * ylims[1],\n",
                "    num=len(rec_list),\n",
                ")\n",
                "\n",
                "# Draw green lines that indicate where retraining occurred\n",
                "plt.hlines(\n",
                "    y=rec_list[\"y_val\"],\n",
                "    xmin=rec_list[0],\n",
                "    xmax=rec_list[1],\n",
                "    color=\"green\",\n",
                "    label=\"Retraining Windows\",\n",
                "    alpha=0.3,\n",
                ")\n",
                "\n",
                "plt.legend()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "EDDM enters a drift state shortly after the drift induction window, triggering\n",
                "retraining. The later increase in the error rate causes the detector to enter\n",
                "the warning state, but is not large enough to be identified as drift with this\n",
                "threshold setting.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.show()\n",
                "# plt.savefig(\"example_EDDM.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Statistical Test of Equal Proportions to Detect Concept Drift (STEPD)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "STEPD is a detector specifically intended for online classifiers, where each new sample is used to update the parameters of the classifier. STEPD monitors the accuracy in two windows, \"recent\" and \"past,\" and compares those in order to detect drift in classifier accuracy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Setup ##\n",
                "\n",
                "np.random.seed(123)\n",
                "df_ex = df\n",
                "train_ix = [0, training_size]\n",
                "\n",
                "\n",
                "# For the purposes of this example, our online classifier is an SGDClassifier\n",
                "# with a constant learning rate, since this is available in the pre-existing\n",
                "# package dependency sklearn.\n",
                "clf = SGDClassifier(learning_rate=\"constant\", shuffle=False, eta0=0.2)\n",
                "clf.fit(\n",
                "    df_ex.loc[train_ix[0] : train_ix[1], [\"var1\", \"var2\"]].values,\n",
                "    df_ex.loc[train_ix[0] : train_ix[1], \"y\"].values,\n",
                ")\n",
                "\n",
                "\n",
                "stepd = STEPD(window_size=100)\n",
                "\n",
                "# setup DF to store results\n",
                "status = pd.DataFrame(columns=[\"index\", \"y\", \"y_pred\", \"drift_detected\", \"accuracy\"])\n",
                "correct = 0\n",
                "rec_list = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# run STEPD and retrain\n",
                "n = 1\n",
                "for i, row in df_ex.iloc[training_size:].iterrows():\n",
                "    y_pred = clf.predict(np.array(row[[\"var1\", \"var2\"]]).reshape(1, -1))\n",
                "    y_true = row[\"y\"]\n",
                "\n",
                "    if y_pred == y_true:\n",
                "        correct += 1\n",
                "    accuracy = correct / n\n",
                "\n",
                "    stepd.update(y_true, y_pred)\n",
                "    status.loc[i] = [i, y_true, y_pred, stepd.drift_state, accuracy]\n",
                "    # train_ix[1] = train_ix[1] + 1\n",
                "\n",
                "    if stepd.drift_state == \"drift\":\n",
                "        rec_list.append(stepd.retraining_recs)\n",
                "        # retrain the classifier using STEPD's recommendations\n",
                "        train_ix = stepd.retraining_recs\n",
                "        train_ix[0] = train_ix[0] + training_size  # adjust for starting index\n",
                "        train_ix[1] = train_ix[1] + training_size\n",
                "        clf.fit(\n",
                "            df_ex.loc[train_ix[0] : train_ix[1], [\"var1\", \"var2\"]].values,\n",
                "            df_ex.loc[train_ix[0] : train_ix[1], \"y\"].values,\n",
                "        )\n",
                "\n",
                "    else:\n",
                "        # update the classifier with the newest sample\n",
                "        clf.partial_fit(row[[\"var1\", \"var2\"]].values.reshape(1, -1), [row[\"y\"]])\n",
                "\n",
                "    n += 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Plotting ##\n",
                "\n",
                "plt.figure(figsize=(20, 6))\n",
                "plt.scatter(\"index\", \"accuracy\", data=status, label=\"Accuracy\")\n",
                "plt.grid(False, axis=\"x\")\n",
                "plt.xticks(fontsize=16)\n",
                "plt.yticks(fontsize=16)\n",
                "plt.title(\"STEPD Results: Accuracy\", fontsize=22)\n",
                "plt.ylabel(\"Value\", fontsize=18)\n",
                "plt.xlabel(\"Index\", fontsize=18)\n",
                "ylims = [-0.05, 1.1]\n",
                "plt.ylim(ylims)\n",
                "\n",
                "plt.axvspan(1000, 1250, alpha=0.5, label=\"Drift Induction Window\")\n",
                "\n",
                "# Draw orange lines that indicate where warnings of drift were provided\n",
                "plt.vlines(\n",
                "    x=status.loc[status[\"drift_detected\"] == \"warning\"][\"index\"],\n",
                "    ymin=ylims[0],\n",
                "    ymax=ylims[1],\n",
                "    label=\"Warning\",\n",
                "    color=\"orange\",\n",
                "    alpha=0.3,\n",
                ")\n",
                "\n",
                "# Draw red lines that indicate where drift was detected\n",
                "plt.vlines(\n",
                "    x=status.loc[status[\"drift_detected\"] == \"drift\"][\"index\"],\n",
                "    ymin=ylims[0],\n",
                "    ymax=ylims[1],\n",
                "    label=\"Drift Detected\",\n",
                "    color=\"red\",\n",
                "    linewidth=3,\n",
                ")\n",
                "\n",
                "# Create a list of lines that indicate the retraining windows.\n",
                "# Space them evenly, vertically.\n",
                "rec_list = pd.DataFrame(rec_list)\n",
                "rec_list[\"y_val\"] = np.linspace(\n",
                "    start=0.05 * (ylims[1] - ylims[0]) + ylims[0],\n",
                "    stop=0.2 * ylims[1],\n",
                "    num=len(rec_list),\n",
                ")\n",
                "\n",
                "# Draw green lines that indicate where retraining occurred\n",
                "plt.hlines(\n",
                "    y=rec_list[\"y_val\"],\n",
                "    xmin=rec_list[0],\n",
                "    xmax=rec_list[1],\n",
                "    color=\"green\",\n",
                "    label=\"Retraining Windows\",\n",
                ")\n",
                "\n",
                "plt.legend(loc='upper left')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "STEPD identifies drift quite early in the drift induction window, triggering\n",
                "retraining on a relatively small amount of data; after this, the online\n",
                "classifier updates sufficiently that its accuracy is roughly flat over the\n",
                "remaining data, albeit with a big enough change to trigger more warnings.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.show()\n",
                "# plt.savefig(\"example_STEPD.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Margin Density Drift Detection (MD3) Method"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "MD3 is a detector intended for semi-supervised and online classifier contexts. A cumulative margin density statistic (unsupervised) is tracked, representing the number of samples that fall into the uncertainty region, or margin, of the classifier. When margin density increases or decreases beyond a certain threshold, a drift warning is issued. When a warning is issued, a set of labeled samples is requested. If prediction accuracy by the model on these samples is lower than on the initial labeled reference dataset, drift is confirmed. If not, drift is ruled out."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Setup ##\n",
                "\n",
                "# Set up classifier: train on first training_size rows\n",
                "training_data = rainfall_df.loc[0:rainfall_training_size, rainfall_columns]\n",
                "X_train = rainfall_df.loc[0:rainfall_training_size, rainfall_features]\n",
                "y_train = rainfall_df.loc[0:rainfall_training_size, \"rain\"]\n",
                "\n",
                "np.random.seed(123)\n",
                "clf = svm.SVC(kernel='linear')\n",
                "clf.fit(X_train, y_train.values.ravel())\n",
                "retrain_clf = clone(clf)\n",
                "retrain_clf.fit(X_train, y_train.values.ravel())\n",
                "oracle_labels = 1000\n",
                "\n",
                "# Initialize detector\n",
                "md3 = MD3(clf=clf, sensitivity=1.5, oracle_data_length_required=oracle_labels)\n",
                "md3.set_reference(X=training_data, target_name=\"rain\")\n",
                "\n",
                "# Set up DF to record results.\n",
                "status = pd.DataFrame(\n",
                "    columns=[\"index\", \"y\", \"margin_density\", \"original_accuracy\", \"retrain_accuracy\", \"drift_detected\"]\n",
                ")\n",
                "correct_orig, correct_retrain = 0, 0\n",
                "n = 1\n",
                "rec_list = []\n",
                "oracle_list = []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# run MD3 and track results for both original model and retrained model\n",
                "for i in range(rainfall_training_size, len(rainfall_df)):\n",
                "\n",
                "    X_test = rainfall_df.loc[[i], rainfall_features]\n",
                "    y_pred_orig = int(clf.predict(X_test))\n",
                "    y_pred_retrain = int(retrain_clf.predict(X_test))\n",
                "    y_true = int(rainfall_df.loc[[i], \"rain\"])\n",
                "    \n",
                "    # increment accuracy\n",
                "    if y_pred_orig == y_true:\n",
                "        correct_orig += 1\n",
                "    if y_pred_retrain == y_true:\n",
                "        correct_retrain += 1\n",
                "    accuracy_orig = correct_orig / n\n",
                "    accuracy_retrain = correct_retrain / n\n",
                "\n",
                "    # call give_oracle_label if detector is currently waiting for oracle data\n",
                "    if md3.waiting_for_oracle == True:\n",
                "        oracle_label = rainfall_df.loc[[i], rainfall_columns]\n",
                "        md3.give_oracle_label(oracle_label)\n",
                "        if md3.waiting_for_oracle == False:\n",
                "            retrain_clf.fit(md3.reference_batch_features, md3.reference_batch_target.values.ravel())\n",
                "        status.loc[i] = [\n",
                "            i,\n",
                "            y_true,\n",
                "            None,\n",
                "            accuracy_orig,\n",
                "            accuracy_retrain,\n",
                "            md3.drift_state,\n",
                "        ]\n",
                "\n",
                "    # call update otherwise\n",
                "    else:\n",
                "        md3.update(X_test)\n",
                "        status.loc[i] = [\n",
                "            i,\n",
                "            y_true,\n",
                "            md3.curr_margin_density,\n",
                "            accuracy_orig,\n",
                "            accuracy_retrain,\n",
                "            md3.drift_state,\n",
                "        ]\n",
                "    \n",
                "    # If there was a drift warning, track the window of the labeled\n",
                "    # oracle data used\n",
                "    if md3.drift_state == \"warning\":\n",
                "        oracle_start = i + 1\n",
                "        oracle_end = i + md3.oracle_data_length_required\n",
                "        \n",
                "        oracle_list.append([oracle_start, oracle_end])\n",
                "\n",
                "    n += 1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Plotting ##\n",
                "\n",
                "plt.figure(figsize=(20, 6))\n",
                "plt.scatter(\"index\", \"margin_density\", data=status, label=\"Margin Density\")\n",
                "plt.scatter(\"index\", \"original_accuracy\", data=status, label=\"Original Accuracy\", color=\"red\")\n",
                "plt.scatter(\"index\", \"retrain_accuracy\", data=status, label=\"Retrain Accuracy\", color=\"green\")\n",
                "plt.grid(False, axis=\"x\")\n",
                "plt.xticks(fontsize=16)\n",
                "plt.yticks(fontsize=16)\n",
                "plt.title(\"MD3 Results: Margin Density and Accuracy\", fontsize=22)\n",
                "plt.ylabel(\"Value\", fontsize=18)\n",
                "plt.xlabel(\"Index\", fontsize=18)\n",
                "ylims = [-0.05, 1.1]\n",
                "plt.ylim(ylims)\n",
                "\n",
                "plt.axvspan(rainfall_drift_start, rainfall_drift_end, alpha=0.5, label=\"Drift Induction Window\")\n",
                "\n",
                "# Draw red lines that indicate where drift was detected\n",
                "plt.vlines(\n",
                "    x=status.loc[status[\"drift_detected\"] == \"drift\"][\"index\"],\n",
                "    ymin=ylims[0],\n",
                "    ymax=ylims[1],\n",
                "    label=\"Drift Detected\",\n",
                "    color=\"red\",\n",
                ")\n",
                "\n",
                "# Draw orange lines that indicate where warnings of drift were provided\n",
                "plt.vlines(\n",
                "    x=status.loc[status[\"drift_detected\"] == \"warning\"][\"index\"],\n",
                "    ymin=ylims[0],\n",
                "    ymax=ylims[1],\n",
                "    label=\"Warning\",\n",
                "    color=\"orange\",\n",
                "    alpha=0.3,\n",
                ")\n",
                "\n",
                "# Create a list of lines that indicate the retraining windows.\n",
                "# Space them evenly, vertically.\n",
                "oracle_list = pd.DataFrame(oracle_list)\n",
                "oracle_list[\"y_val\"] = np.linspace(\n",
                "    start=0.05 * (ylims[1] - ylims[0]) + ylims[0],\n",
                "    stop=0.2 * ylims[1],\n",
                "    num=len(oracle_list),\n",
                ")\n",
                "\n",
                "# Draw green lines that indicate where retraining occurred\n",
                "plt.hlines(\n",
                "    y=oracle_list[\"y_val\"],\n",
                "    xmin=oracle_list[0],\n",
                "    xmax=oracle_list[1],\n",
                "    color=\"green\",\n",
                "    label=\"Labeled Oracle Data\",\n",
                ")\n",
                "\n",
                "plt.legend()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After drift is induced, the margin density decreases enough for MD3 to emit a warning. From there, the predictive accuracy of the classifier is tested, and this has already decreased sufficiently for the detector to alarm. Then, a new reference batch is set and the detector continues tracking the margin density statistic until the next warning. It can be seen from the plot that retraining at drift results in better accuracy moving forward compared with a model that is kept static."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.show()\n",
                "# plt.savefig(\"example_MD3.png\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.2 ('molten_env')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.2"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "cebda30e5482c3c83cb9c7c7d8ef1c1d1f67dcf93284b9e88f69b68f560a7bf6"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
